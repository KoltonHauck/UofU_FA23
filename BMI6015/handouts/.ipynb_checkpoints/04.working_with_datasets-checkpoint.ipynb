{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Working with datasets\n",
    "\n",
    "It's important to have a clear and sensible way of representing datasets. In machine learning a dataset is a table that consists of $n$ rows. Each row is called an example or a sample. Its columns are divided into two input and output portion. The input portion consists of $m$ columns called features. In other words, $m$ represent the dimensionality of the dataset. The IRIS dataset, for example, has *4* input features, meaning that it is a dataset with a dimensionality of *4*. The output portion exists only in supervised learning. It consists of one or more columns called targets.\n",
    "\n",
    "Mathematically, a supervised learning dataset can be thought of as a matrix of the form:\n",
    "\n",
    "$\\boldsymbol{D} =\\left[\\begin{array}{cccccc} \n",
    "  x_1^{(1)} & x_2^{(1)} & x_3^{(1)} & \\cdots & x_m^{(1)} & y^{(1)}\\\\ \n",
    "  x_1^{(2)} & x_2^{(2)} & x_3^{(2)} & \\cdots & x_m^{(2)} & y^{(2)}\\\\\n",
    "  x_1^{(3)} & x_2^{(3)} & x_3^{(3)} & \\cdots & x_m^{(3)} & y^{(3)}\\\\\n",
    "  \\vdots    & \\vdots    & \\vdots    & \\cdots & \\vdots & \\vdots \\\\\n",
    "  x_1^{(n)} & x_2^{(n)} & x_3^{(n)} & \\cdots & x_m^{(n)} & y^{(n)}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "As you can see, each row of this matrix is a data example consisting of the $m$ input features plus the target column (typically the last column). The $\\boldsymbol{D}$ matrix can be broken into two components: the input matrix $\\boldsymbol{X}$ and the target vector $y$, where: \n",
    "\n",
    "$\\boldsymbol{X} =\\left[\\begin{array}{ccccc} \n",
    "  x_1^{(1)} & x_2^{(1)} & x_3^{(1)} & \\cdots & x_m^{(1)}\\\\ \n",
    "  x_1^{(2)} & x_2^{(2)} & x_3^{(2)} & \\cdots & x_m^{(2)}\\\\\n",
    "  x_1^{(3)} & x_2^{(3)} & x_3^{(3)} & \\cdots & x_m^{(3)}\\\\\n",
    "  \\vdots    & \\vdots    & \\vdots    & \\cdots & \\vdots \\\\\n",
    "  x_1^{(n)} & x_2^{(n)} & x_3^{(n)} & \\cdots & x_m^{(n)}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "and\n",
    "\n",
    "$\\boldsymbol{y} =\\left[\\begin{array}{c} \n",
    "  y^{(1)}\\\\ \n",
    "  y^{(2)}\\\\\n",
    "  y^{(3)}\\\\\n",
    "  \\vdots \\\\\n",
    "  y^{(n)}\n",
    "\\end{array}\\right]$\n",
    "\n",
    "For unsupervised learning, $\\boldsymbol{D}$ is the same as $\\boldsymbol{X}$; no target vector.\n",
    "\n",
    "We can use a Python class to represent datasets, but that would be unnecessary. We will instead use Numpy arrays and sometimes Pandas's Dataframes for representing datasets. This is the approach that popular machine learning library `scikit-learn` follows, and we will do the same.\n",
    "\n",
    "Here is an example dataset with three input features and one target. We start with the input feature matrix $\\mathbf{X}$; the use of the uppercase $\\mathbf{X}$ indicates being a matrix with more than one column. The target column is typically called $\\mathbf{y}$; the use of the lowercase $\\mathbf{y}$ indicates a vector (one column).\n",
    "\n",
    "Here is the input matrix $\\mathbf{X}$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  3.        ,  9.08571715],\n",
       "       [ 3.        ,  4.        , 11.02867118],\n",
       "       [ 4.        ,  4.        , 12.49777946],\n",
       "       [ 2.        ,  8.        , 10.99971967],\n",
       "       [ 5.        ,  6.        ,  9.27535658],\n",
       "       [ 3.        ,  5.        ,  9.29852643],\n",
       "       [ 5.        ,  7.        , 11.67872293],\n",
       "       [ 3.        ,  8.        ,  7.99787447],\n",
       "       [ 2.        ,  2.        ,  8.52725862],\n",
       "       [ 4.        ,  1.        , 12.75729435],\n",
       "       [ 4.        ,  3.        , 12.77159384],\n",
       "       [ 3.        ,  6.        ,  9.28819879],\n",
       "       [ 3.        ,  5.        ,  9.36185114],\n",
       "       [ 3.        ,  8.        ,  8.37275863],\n",
       "       [ 4.        ,  6.        ,  8.07569704],\n",
       "       [ 2.        ,  3.        ,  9.61295022],\n",
       "       [ 2.        ,  2.        , 11.79023666],\n",
       "       [ 4.        ,  3.        ,  9.82731865],\n",
       "       [ 3.        ,  4.        ,  9.71159121],\n",
       "       [ 2.        ,  1.        , 11.89886391],\n",
       "       [ 3.        ,  1.        ,  9.20477673],\n",
       "       [ 4.        ,  5.        ,  6.9443438 ],\n",
       "       [ 2.        ,  6.        , 13.93357835],\n",
       "       [ 3.        ,  8.        , 10.06203902],\n",
       "       [ 5.        ,  4.        ,  8.55348133],\n",
       "       [ 5.        ,  1.        ,  7.77851658],\n",
       "       [ 2.        ,  1.        , 10.82418181]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array([\n",
    "        np.random.randint(2,6, 27),                # x1\n",
    "        np.random.randint(1,9, 27),                # x2\n",
    "        np.random.normal(loc=10, scale=2, size=27) # x3\n",
    "    ]).T\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the target $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.randint(0,2, 27)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use both components $\\mathbf{X}$ and $\\mathbf{y}$ to create the full dataset  $\\mathbf{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  3.        ,  9.08571715,  0.        ],\n",
       "       [ 3.        ,  4.        , 11.02867118,  1.        ],\n",
       "       [ 4.        ,  4.        , 12.49777946,  0.        ],\n",
       "       [ 2.        ,  8.        , 10.99971967,  1.        ],\n",
       "       [ 5.        ,  6.        ,  9.27535658,  1.        ],\n",
       "       [ 3.        ,  5.        ,  9.29852643,  0.        ],\n",
       "       [ 5.        ,  7.        , 11.67872293,  1.        ],\n",
       "       [ 3.        ,  8.        ,  7.99787447,  1.        ],\n",
       "       [ 2.        ,  2.        ,  8.52725862,  0.        ],\n",
       "       [ 4.        ,  1.        , 12.75729435,  0.        ],\n",
       "       [ 4.        ,  3.        , 12.77159384,  1.        ],\n",
       "       [ 3.        ,  6.        ,  9.28819879,  0.        ],\n",
       "       [ 3.        ,  5.        ,  9.36185114,  0.        ],\n",
       "       [ 3.        ,  8.        ,  8.37275863,  1.        ],\n",
       "       [ 4.        ,  6.        ,  8.07569704,  1.        ],\n",
       "       [ 2.        ,  3.        ,  9.61295022,  0.        ],\n",
       "       [ 2.        ,  2.        , 11.79023666,  1.        ],\n",
       "       [ 4.        ,  3.        ,  9.82731865,  1.        ],\n",
       "       [ 3.        ,  4.        ,  9.71159121,  0.        ],\n",
       "       [ 2.        ,  1.        , 11.89886391,  1.        ],\n",
       "       [ 3.        ,  1.        ,  9.20477673,  1.        ],\n",
       "       [ 4.        ,  5.        ,  6.9443438 ,  1.        ],\n",
       "       [ 2.        ,  6.        , 13.93357835,  0.        ],\n",
       "       [ 3.        ,  8.        , 10.06203902,  0.        ],\n",
       "       [ 5.        ,  4.        ,  8.55348133,  0.        ],\n",
       "       [ 5.        ,  1.        ,  7.77851658,  0.        ],\n",
       "       [ 2.        ,  1.        , 10.82418181,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.concatenate([X, y.reshape(len(X), -1)], axis=1)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using dataframes\n",
    "\n",
    "To display this dataset in a nice tabular format with column headings, we can use a Pandas' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.085717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.028671</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.497779</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.999720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.275357</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.298526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.678723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.997874</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.527259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.757294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.771594</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.288199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.361851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.372759</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.075697</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.612950</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.790237</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.827319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.711591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.898864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.204777</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.944344</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.933578</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.062039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.553481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.778517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.824182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1   x2         x3    y\n",
       "0   2.0  3.0   9.085717  0.0\n",
       "1   3.0  4.0  11.028671  1.0\n",
       "2   4.0  4.0  12.497779  0.0\n",
       "3   2.0  8.0  10.999720  1.0\n",
       "4   5.0  6.0   9.275357  1.0\n",
       "5   3.0  5.0   9.298526  0.0\n",
       "6   5.0  7.0  11.678723  1.0\n",
       "7   3.0  8.0   7.997874  1.0\n",
       "8   2.0  2.0   8.527259  0.0\n",
       "9   4.0  1.0  12.757294  0.0\n",
       "10  4.0  3.0  12.771594  1.0\n",
       "11  3.0  6.0   9.288199  0.0\n",
       "12  3.0  5.0   9.361851  0.0\n",
       "13  3.0  8.0   8.372759  1.0\n",
       "14  4.0  6.0   8.075697  1.0\n",
       "15  2.0  3.0   9.612950  0.0\n",
       "16  2.0  2.0  11.790237  1.0\n",
       "17  4.0  3.0   9.827319  1.0\n",
       "18  3.0  4.0   9.711591  0.0\n",
       "19  2.0  1.0  11.898864  1.0\n",
       "20  3.0  1.0   9.204777  1.0\n",
       "21  4.0  5.0   6.944344  1.0\n",
       "22  2.0  6.0  13.933578  0.0\n",
       "23  3.0  8.0  10.062039  0.0\n",
       "24  5.0  4.0   8.553481  0.0\n",
       "25  5.0  1.0   7.778517  0.0\n",
       "26  2.0  1.0  10.824182  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.DataFrame(D, columns=['x1', 'x2', 'x3', 'y'])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generalize moving data back and forth between NumPy arrays and Pandas' dataframes, here are a few functions.\n",
    "* `to_dataframe`: coverts NumPy $\\mathbf{X}$ and $\\mathbf{y}$ arrays into a dataframe $\\mathbf{D}$.\n",
    "* `from_dataframe`: converts a dataframe $\\mathbf{D}$ to NumPy $\\mathbf{X}$ and $\\mathbf{y}$ arrays.\n",
    "* `print_dataset`: prints NumPy $\\mathbf{X}$ and $\\mathbf{y}$ arrays in a nice tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(X, y=None, features=None, target=None):\n",
    "    \"\"\"\n",
    "    Puts X and y into a data frame and prints it.\n",
    "    - X, y: The input and target data.\n",
    "    - features: The names of the input data features.\n",
    "    - target: The name of the target column.\n",
    "    \"\"\"\n",
    "    M = X.shape[1]\n",
    "    columns = [ f\"x{i + 1}\" for i in range(M) ] if features is None else features\n",
    "        \n",
    "    if y is not None:\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(len(X), -1)\n",
    "            \n",
    "        T = y.shape[1] # number of target columns\n",
    "        if T == 1:\n",
    "            columns.append(\"y\" if target is None else target)\n",
    "        else:\n",
    "            columns += [ f\"y{i + 1}\" for i in range(T) ] if target is None else target\n",
    "     \n",
    "    return pd.DataFrame(np.concatenate([X, y], axis=1), columns=columns)\n",
    "    \n",
    "def from_dataframe(df, ntargets=1):\n",
    "    \"\"\"\n",
    "    Separates a given data frame into Numpy input and target arrays.\n",
    "    - df: The data frame \n",
    "    - ntargets: The number of target columns at the end of the data frame.\n",
    "    \"\"\"\n",
    "    ntargets = 0 if ntargets is None else ntargets\n",
    "    if ntargets > 0:\n",
    "        X = df.iloc[:, :-ntargets].values.squeeze()\n",
    "        y = df.iloc[:, -ntargets:].values.squeeze()\n",
    "        features = list(df.columns[:-ntargets])\n",
    "        targets = list(df.columns[-ntargets:])\n",
    "        \n",
    "        return X, y, features, targets\n",
    "    else:\n",
    "        X = df.values\n",
    "        features = list(df.columns)\n",
    "        \n",
    "        return X, features\n",
    "\n",
    "def print_dataset(X, y=None, name=None, features=None, target=None):\n",
    "    \"\"\"\n",
    "    Puts X and y into a data frame and prints it.\n",
    "    - X, y: The input and target data.\n",
    "    - features: The names of the input data features.\n",
    "    - target: The name of the target column.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        print(name)\n",
    "        \n",
    "    print(to_dataframe(X, y=y, features=features, target=target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the above datasets prints using the `print_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x1   x2         x3    y\n",
      "0   2.0  3.0   9.085717  0.0\n",
      "1   3.0  4.0  11.028671  1.0\n",
      "2   4.0  4.0  12.497779  0.0\n",
      "3   2.0  8.0  10.999720  1.0\n",
      "4   5.0  6.0   9.275357  1.0\n",
      "5   3.0  5.0   9.298526  0.0\n",
      "6   5.0  7.0  11.678723  1.0\n",
      "7   3.0  8.0   7.997874  1.0\n",
      "8   2.0  2.0   8.527259  0.0\n",
      "9   4.0  1.0  12.757294  0.0\n",
      "10  4.0  3.0  12.771594  1.0\n",
      "11  3.0  6.0   9.288199  0.0\n",
      "12  3.0  5.0   9.361851  0.0\n",
      "13  3.0  8.0   8.372759  1.0\n",
      "14  4.0  6.0   8.075697  1.0\n",
      "15  2.0  3.0   9.612950  0.0\n",
      "16  2.0  2.0  11.790237  1.0\n",
      "17  4.0  3.0   9.827319  1.0\n",
      "18  3.0  4.0   9.711591  0.0\n",
      "19  2.0  1.0  11.898864  1.0\n",
      "20  3.0  1.0   9.204777  1.0\n",
      "21  4.0  5.0   6.944344  1.0\n",
      "22  2.0  6.0  13.933578  0.0\n",
      "23  3.0  8.0  10.062039  0.0\n",
      "24  5.0  4.0   8.553481  0.0\n",
      "25  5.0  1.0   7.778517  0.0\n",
      "26  2.0  1.0  10.824182  0.0\n"
     ]
    }
   ],
   "source": [
    "print_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling data\n",
    "\n",
    "Datasets are almost always shuffled before being used for training. Here is a function for doing so. The `random_state` parameter is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled(X, y, random_state=None):\n",
    "    \"\"\"\n",
    "    Shuffles the X, y.\n",
    "    \"\"\"\n",
    "    rgen = np.random.RandomState(random_state)\n",
    "    \n",
    "    indexes = rgen.permutation(len(X))\n",
    "    \n",
    "    return X[indexes], y[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.        ,  3.        ,  9.82731865],\n",
       "        [ 2.        ,  2.        , 11.79023666],\n",
       "        [ 4.        ,  1.        , 12.75729435],\n",
       "        [ 3.        ,  8.        ,  7.99787447],\n",
       "        [ 2.        ,  2.        ,  8.52725862],\n",
       "        [ 3.        ,  4.        , 11.02867118],\n",
       "        [ 3.        ,  4.        ,  9.71159121],\n",
       "        [ 2.        ,  1.        , 10.82418181],\n",
       "        [ 2.        ,  3.        ,  9.08571715],\n",
       "        [ 3.        ,  5.        ,  9.29852643],\n",
       "        [ 5.        ,  7.        , 11.67872293],\n",
       "        [ 3.        ,  5.        ,  9.36185114],\n",
       "        [ 5.        ,  6.        ,  9.27535658],\n",
       "        [ 3.        ,  8.        ,  8.37275863],\n",
       "        [ 5.        ,  4.        ,  8.55348133],\n",
       "        [ 5.        ,  1.        ,  7.77851658],\n",
       "        [ 3.        ,  6.        ,  9.28819879],\n",
       "        [ 3.        ,  1.        ,  9.20477673],\n",
       "        [ 4.        ,  5.        ,  6.9443438 ],\n",
       "        [ 3.        ,  8.        , 10.06203902],\n",
       "        [ 4.        ,  3.        , 12.77159384],\n",
       "        [ 2.        ,  6.        , 13.93357835],\n",
       "        [ 4.        ,  4.        , 12.49777946],\n",
       "        [ 4.        ,  6.        ,  8.07569704],\n",
       "        [ 2.        ,  8.        , 10.99971967],\n",
       "        [ 2.        ,  1.        , 11.89886391],\n",
       "        [ 2.        ,  3.        ,  9.61295022]]),\n",
       " array([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "Another useful operation commonly performed on datasets is splitting them into training and testing sets. Here is a function that does that.\n",
    "\n",
    "If the `start` and  `end` parameters exist, the method returns the examples before them as test and the rest of the data as training. If `test_size` is provided, then that portion of the data is returned as test and the rest as training. The `shuffle` parameter can be used to instruct the method to shuffle the data before splitting it. The method finally returns two dataset instances: training and test sets.\n",
    "\n",
    "Here is an example using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=.25, shuffle=True, random_state=None):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a training set and a test set. If test_portion \n",
    "    is specified, return that portion of the dataset as test and the rest \n",
    "    as training.\n",
    "    \"\"\"\n",
    "    if shuffle is True:\n",
    "        rgen = np.random.RandomState(random_state)\n",
    "        indexes = rgen.permutation(len(X))\n",
    "        X, y = X[indexes], y[indexes]\n",
    "\n",
    "    if not isinstance(test_size, float) or test_size < 0.0 or test_size > 1.0:\n",
    "        raise TypeError(\"Only fractions between ]0,1[ are allowed for test_size.\")\n",
    "\n",
    "    split_ndx = int(test_size * len(X))\n",
    "    \n",
    "    if y.ndim == 1:\n",
    "        return X[split_ndx:, :], X[0:split_ndx, :], y[split_ndx:], y[0:split_ndx]\n",
    "    else:\n",
    "        return X[split_ndx:, :], X[0:split_ndx, :], y[split_ndx:, :], y[0:split_ndx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "     x1   x2         x3    y\n",
      "0   3.0  8.0  10.062039  0.0\n",
      "1   4.0  5.0   6.944344  1.0\n",
      "2   2.0  8.0  10.999720  1.0\n",
      "3   4.0  4.0  12.497779  0.0\n",
      "4   4.0  3.0  12.771594  1.0\n",
      "5   2.0  2.0   8.527259  0.0\n",
      "6   4.0  1.0  12.757294  0.0\n",
      "7   5.0  4.0   8.553481  0.0\n",
      "8   4.0  6.0   8.075697  1.0\n",
      "9   3.0  4.0  11.028671  1.0\n",
      "10  3.0  4.0   9.711591  0.0\n",
      "11  3.0  5.0   9.361851  0.0\n",
      "12  3.0  8.0   7.997874  1.0\n",
      "13  5.0  6.0   9.275357  1.0\n",
      "14  3.0  8.0   8.372759  1.0\n",
      "15  2.0  2.0  11.790237  1.0\n",
      "16  2.0  6.0  13.933578  0.0\n",
      "17  5.0  7.0  11.678723  1.0\n",
      "18  2.0  1.0  10.824182  0.0\n",
      "19  4.0  3.0   9.827319  1.0\n",
      "20  2.0  3.0   9.612950  0.0\n",
      "Testing Dataset\n",
      "    x1   x2         x3    y\n",
      "0  5.0  1.0   7.778517  0.0\n",
      "1  2.0  3.0   9.085717  0.0\n",
      "2  2.0  1.0  11.898864  1.0\n",
      "3  3.0  1.0   9.204777  1.0\n",
      "4  3.0  5.0   9.298526  0.0\n",
      "5  3.0  6.0   9.288199  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((21, 3), (6, 3), (21,), (6,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "print_dataset(X_train, y_train, name=\"Training Dataset\")\n",
    "print_dataset(X_test, y_test, name=\"Testing Dataset\")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `mylib` package\n",
    "\n",
    "The above functions will be used in the upcoming weeks of this class. To facilitate such usage, they have been placed inside a simple for-this-class-only package named `mylib`, which you can download from GitHub at https://github.com/aalgahmi/mylib. Here is how you can use the `git` command-line to do so:\n",
    "\n",
    "* Open a terminal window and change its current directory to where your handout notebooks are. For example:\n",
    "  ```\n",
    "  cd handouts\n",
    "  \n",
    "  \n",
    "  ```\n",
    "  \n",
    "  Notice that can launch a terminal from inside Jupyter Lab using the menu **File/New/Terminal**.\n",
    "* Run the following command to download this package (clone it) from GitHub:\n",
    "\n",
    "  ```\n",
    "  git clone https://github.com/aalgahmi/mylib.git\n",
    "  ```\n",
    "\n",
    "This will only need to be done once. After that, you can import this package using a statement like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylib as my"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once imported, let's create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    np.random.randint(-2,3, 30),\n",
    "    np.random.randint(1,2, 30)]).T\n",
    "\n",
    "y = np.array([\n",
    "    np.random.randint(0,3, 30),\n",
    "    np.random.randint(2,4, 30)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this library to print this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a1  a2  t1  t2\n",
      "0    2   1   2   2\n",
      "1   -1   1   1   2\n",
      "2   -2   1   2   3\n",
      "3    2   1   0   3\n",
      "4    2   1   0   2\n",
      "5   -2   1   1   2\n",
      "6   -1   1   1   3\n",
      "7   -1   1   1   3\n",
      "8    0   1   0   3\n",
      "9    0   1   0   3\n",
      "10   1   1   0   2\n",
      "11  -1   1   2   3\n",
      "12   2   1   0   2\n",
      "13   1   1   2   3\n",
      "14   2   1   1   2\n",
      "15  -1   1   0   2\n",
      "16  -1   1   2   3\n",
      "17   2   1   1   2\n",
      "18  -1   1   1   3\n",
      "19   0   1   0   3\n",
      "20   1   1   0   2\n",
      "21   2   1   0   2\n",
      "22  -2   1   2   2\n",
      "23   0   1   1   2\n",
      "24  -1   1   2   2\n",
      "25   2   1   2   3\n",
      "26   1   1   0   2\n",
      "27   1   1   1   2\n",
      "28   2   1   0   3\n",
      "29   1   1   1   3\n"
     ]
    }
   ],
   "source": [
    "my.print_dataset(X, y, target=['t1', 't2'], features=['a1', 'a2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And one can use the `train_test_split` to shuffle and split this data set into two sets for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 2), (9, 2), (21, 2), (9, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = my.train_test_split(X, y, test_size=.33, random_state=17)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print these splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "    x1  x2  y1  y2\n",
      "0    1   1   0   2\n",
      "1    2   1   0   3\n",
      "2   -2   1   2   3\n",
      "3    1   1   0   2\n",
      "4    0   1   0   3\n",
      "5    0   1   0   3\n",
      "6    2   1   0   3\n",
      "7    2   1   1   2\n",
      "8   -1   1   1   2\n",
      "9    1   1   0   2\n",
      "10   2   1   0   2\n",
      "11  -1   1   1   3\n",
      "12   2   1   0   2\n",
      "13   2   1   2   3\n",
      "14   1   1   2   3\n",
      "15  -1   1   2   3\n",
      "16  -2   1   2   2\n",
      "17  -1   1   1   3\n",
      "18   1   1   1   3\n",
      "19   2   1   1   2\n",
      "20  -1   1   0   2\n"
     ]
    }
   ],
   "source": [
    "my.print_dataset(X_train, y_train, name=\"Training Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dataset\n",
      "   x1  x2  y1  y2\n",
      "0   2   1   2   2\n",
      "1  -1   1   1   3\n",
      "2   2   1   0   2\n",
      "3  -1   1   2   3\n",
      "4  -2   1   1   2\n",
      "5   0   1   1   2\n",
      "6   1   1   1   2\n",
      "7   0   1   0   3\n",
      "8  -1   1   2   2\n"
     ]
    }
   ],
   "source": [
    "my.print_dataset(X_test, y_test, name=\"Testing Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducting `scikit-learn`\n",
    "\n",
    "Scikit-learn is a popular general-purpose machine learning library for Python programmers. It is \"an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.\" \n",
    "\n",
    "The `scikit-learn` library is very well-designed [This paper](https://arxiv.org/abs/1309.0238) outlines the main design principles that went into its creation. In a nutshell, they are: \n",
    "\n",
    "**Consistency**\n",
    "All objects share a consistent and simple interface that distinguishes between three different kinds of objects:\n",
    "\n",
    "* **Estimators**: Any object that can estimate some parameters based on a dataset is called an estimator. All estimators implement a `fit()` method. This is where the estimation (learning) itself is performed.\n",
    "* **Transformers**: These are estimators that can transform datasets. The transformation is performed by the `transform()` method. All transformers also have a convenient method called `fit_transform()`, which is equivalent to calling `fit()` and then `transform()`.\n",
    "\n",
    "* **Predictors**: Some estimators, like those of supervised learning, are capable of making predictions and therefore are called predictors. All predictors implement two methods: a `predict()` and a `score()`. While the `predict()` method returns the predicted values, the `score()` method returns a measure of the quality of these predictions (for example accuracy for classification problems, and coefficient of determination $R^2$ for regression problems).\n",
    "\n",
    "**Inspection**\n",
    "All hyperparameters are accessible as public instance variables, and all learned (estimated from data) parameters are accessible as public instance variables with an underscore suffix.\n",
    "\n",
    "**Nonproliferation of classes**\n",
    "Datasets are represented as NumPy arrays or SciPy sparse matrices. Classes are used for estimators, transformers, and predictors.\n",
    "\n",
    "**Composition**\n",
    "New estimators can be created from existing building blocks. This done using pipelines and feature unions.\n",
    "\n",
    "**Sensible defaults**\n",
    "Finally, `scikit-learn` provides reasonable default values for most parameters, making it easier to use.\n",
    "\n",
    "As you use the classes and functions of `scikit-learn`, make sure to always reference [their documentation pages](https://scikit-learn.org/stable/) for explanations and code examples.\n",
    "\n",
    "Let's import `scikit-learn`, inspect its version, and use it split a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the current version we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` consists of multiple packages/modules. One such package is called `datasets`. It contains a few popular sample datasets as well as various functions for creating sample datasets. Let's use this package to load the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `X` is a 4-dimensional input array with 150 examples (also known as samples or rows), and `y` is the target (output or ground truth) column with three classes (encoded as 0, 1, and 2) representing following Iris flower types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how this dataset looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1   x2   x3   x4    y\n",
       "0    5.1  3.5  1.4  0.2  0.0\n",
       "1    4.9  3.0  1.4  0.2  0.0\n",
       "2    4.7  3.2  1.3  0.2  0.0\n",
       "3    4.6  3.1  1.5  0.2  0.0\n",
       "4    5.0  3.6  1.4  0.2  0.0\n",
       "..   ...  ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3  2.0\n",
       "146  6.3  2.5  5.0  1.9  2.0\n",
       "147  6.5  3.0  5.2  2.0  2.0\n",
       "148  6.2  3.4  5.4  2.3  2.0\n",
       "149  5.9  3.0  5.1  1.8  2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my.to_dataframe(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in `scikit-learn`\n",
    "\n",
    "To train supervised machine learning models to recognize these flower types, we need to split the dataset into two portions: training and testing. We can use the `train_test_split` from the `model_selection` package to do that. This function will automatically shuffle the data and can be called in the same way as the above `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120,), (30,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where X_? represents the input portion of the ? dataset and y_? the output portion. We'll set the test dataset aside for now. Let's print the first few examples of the training dataset and make sure that it's shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.8, 2.8, 4.8, 1.4],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [6.9, 3.1, 5.4, 2.1]]),\n",
       " array([1, 2, 0, 2, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5, :], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE\n",
    "\n",
    "Do Exercise 2 - PART A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
