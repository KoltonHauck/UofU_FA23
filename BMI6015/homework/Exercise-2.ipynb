{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64deb005-9478-4bae-8568-e03828daefe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5667b8-f52d-475c-a5d3-bc8b61914ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5112a-375e-474d-80db-4b5e863f63a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913d0de-a988-44a8-ba87-4f1e80dd2675",
   "metadata": {},
   "source": [
    "**(30 points)** Write a function named `data_split` that splits a given dataset into a specified number of subsets, as determined by the `portions` parameter. The function should look like:\n",
    "\n",
    "```python\n",
    "def data_split(X, y, portions, shuffle=True):\n",
    "    # TODO\n",
    "```\n",
    "\n",
    "where `X` and `y` are both The portions should be outlined in a dictionary format. For instance, invoking:\n",
    "\n",
    "```python\n",
    "data_split(X, y, portions={\"training\": .75, 'validation': .15, 'test': .10 })\n",
    "```\n",
    "\n",
    "will return a dictionary containing the divided sets. The returned dictionary's keys correspond to the indicated portions, while the values represent the input and output data of the splits. By default, the function should randomly shuffle the data before splitting.\n",
    "\n",
    "**IMPORTANT:** If the sum of the requested portions exceeds 1, normalize them, ensuring their total equals 1. If the sum falls below 1, an additional entry should be added into the portions dictionary. This entry's key should be named 'remaining', and its value should be one minus the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f55f469-53d6-410c-81d7-35fd8e7e39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_split(X, y, portions, shuffle=True):\n",
    "    #ensure X and y are same lengths\n",
    "    if len(X) != len(y):\n",
    "        print('X and y are not same length')\n",
    "        return\n",
    "    \n",
    "    #ensure sums of portions == 1\n",
    "    portions_sum = sum([portions[i] for i in portions])\n",
    "    if portions_sum > 1:\n",
    "        print('Portions sum > 1...normalizing')\n",
    "        for dataset in portions:\n",
    "            portions[dataset] /= portions_sum\n",
    "            \n",
    "    portions_sum = sum([portions[i] for i in portions])\n",
    "    if portions_sum < 1:\n",
    "        print('Portions sum < 1...adding \"remaining\" portion...')\n",
    "        portions['remaining'] = 1 - portions_sum\n",
    "    \n",
    "    #shuffle if shuffle\n",
    "    if shuffle:\n",
    "        permutation = np.random.permutation(len(X))\n",
    "        X, y =  X[permutation], y[permutation]\n",
    "      \n",
    "    #get split indices\n",
    "    tmp = [int(portion * len(X)) for portion in portions.values()]\n",
    "    splits = []\n",
    "    curr = 0\n",
    "    for item in range(len(tmp) - 1):\n",
    "        curr += tmp[item]\n",
    "        splits.append(curr)\n",
    "    splits.append(len(X))\n",
    "    splits = [0] + splits  \n",
    "    \n",
    "    #split datasets\n",
    "    divided = {}\n",
    "    for i in range(len(splits)-1):\n",
    "        currX =  X[splits[i]:splits[i+1],:]\n",
    "        curry = y[splits[i]:splits[i+1]]\n",
    "        divided[list(portions.keys())[i]] = [currX, curry]\n",
    "    \n",
    "    return divided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1c1d9-2777-4119-bee7-eade7c1f3b5d",
   "metadata": {},
   "source": [
    "**(20 points)** Test your function on the IRIS dataset using the following four different split scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9106a5ab-6828-4121-b82f-63b13c8470b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b2c75e-5355-45f3-b182-575f54e62840",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['training', 'testing'])\n",
      "trainingX shape: (105, 4)\n",
      "trainingy shape: (105,)\n",
      "testingX shape: (45, 4)\n",
      "testingy shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "# Test scenario 1: A 70/30 training/testing split.\n",
    "test1 = data_split(X, y, {'training': .7, 'testing': .3})\n",
    "print(test1.keys())\n",
    "print('trainingX shape:', test1['training'][0].shape)\n",
    "print('trainingy shape:', test1['training'][1].shape)\n",
    "\n",
    "print('testingX shape:', test1['testing'][0].shape)\n",
    "print('testingy shape:', test1['testing'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f5eea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['training', 'validation', 'testing'])\n",
      "trainingX shape: (90, 4)\n",
      "trainingy shape: (90,)\n",
      "validationX shape: (37, 4)\n",
      "validationy shape: (37,)\n",
      "testingX shape: (23, 4)\n",
      "testingy shape: (23,)\n"
     ]
    }
   ],
   "source": [
    "# Test scenario 2: A 60/25/15 training/validation/testing split.\n",
    "test2 = data_split(X, y, {'training': .60, 'validation': .25, 'testing': .15})\n",
    "print(test2.keys())\n",
    "print('trainingX shape:', test2['training'][0].shape)\n",
    "print('trainingy shape:', test2['training'][1].shape)\n",
    "\n",
    "print('validationX shape:', test2['validation'][0].shape)\n",
    "print('validationy shape:', test2['validation'][1].shape)\n",
    "\n",
    "print('testingX shape:', test2['testing'][0].shape)\n",
    "print('testingy shape:', test2['testing'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d61aca3-d929-4c01-bf31-a55c3b99f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portions sum > 1...normalizing\n",
      "Portions sum < 1...adding \"remaining\" portion...\n",
      "dict_keys(['training', 'validation', 'testing', 'remaining'])\n",
      "trainingX shape: (62, 4)\n",
      "trainingy shape: (62,)\n",
      "validationX shape: (37, 4)\n",
      "validationy shape: (37,)\n",
      "testingX shape: (50, 4)\n",
      "testingy shape: (50,)\n",
      "remainingX shape: (1, 4)\n",
      "remainingy shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Test scenario 3: A 50/30/40 training/validation/testing split.\n",
    "test3 = data_split(X, y, {'training': .50, 'validation': .30, 'testing': .40})\n",
    "print(test3.keys())\n",
    "print('trainingX shape:', test3['training'][0].shape)\n",
    "print('trainingy shape:', test3['training'][1].shape)\n",
    "\n",
    "print('validationX shape:', test3['validation'][0].shape)\n",
    "print('validationy shape:', test3['validation'][1].shape)\n",
    "\n",
    "print('testingX shape:', test3['testing'][0].shape)\n",
    "print('testingy shape:', test3['testing'][1].shape)\n",
    "\n",
    "print('remainingX shape:', test3['remaining'][0].shape)\n",
    "print('remainingy shape:', test3['remaining'][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b3dce8-d540-4b3e-9783-644756096327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portions sum < 1...adding \"remaining\" portion...\n",
      "dict_keys(['testing', 'remaining'])\n",
      "testingX shape: (45, 4)\n",
      "testingy shape: (45,)\n",
      "remainingX shape: (105, 4)\n",
      "remainingy shape: (105,)\n"
     ]
    }
   ],
   "source": [
    "# Test scenario 4: A 30 testing split.\n",
    "test4 = data_split(X, y, {'testing': .30})\n",
    "print(test4.keys())\n",
    "print('testingX shape:', test4['testing'][0].shape)\n",
    "print('testingy shape:', test4['testing'][1].shape)\n",
    "\n",
    "print('remainingX shape:', test4['remaining'][0].shape)\n",
    "print('remainingy shape:', test4['remaining'][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dab4a-84cb-4b3e-a927-8f5116aa79c9",
   "metadata": {},
   "source": [
    "## PART B "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33d50e-1723-4a56-a5d0-c46a4f88f208",
   "metadata": {},
   "source": [
    "**(30 points)** Write a function that accepts a confusion matrix with more than two classes (for example, a confusion matrix with 3 classes: A, B, and C), alongside a class index (like 0, 1, or 2). The function should return the sensitivity (recall), specificity, precision, and F1 metrics for the specified class index.\n",
    "\n",
    "**HINT**: Convert the confusion matrix into a  $2 \\times 2$  matrix that represents the designated class versus all other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f65dbd3-8d44-4780-a43a-f2e4bb593861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming top axis is actual, left is predicted\n",
    "def cm_to_2x2(cm, i):\n",
    "    new = np.zeros(shape=(2,2))\n",
    "    \n",
    "    #true positives\n",
    "    tp = cm[i,i]\n",
    "    #false negatives\n",
    "    fn = sum(cm[:,i]) - tp\n",
    "    #false positives\n",
    "    fp = sum(cm[i,:]) - tp\n",
    "    #true negatives\n",
    "    tn = cm.sum() - tp - fn - fp\n",
    "    \n",
    "    #set true positives for indicated index into 0,0\n",
    "    new[0,0] = tp\n",
    "    #set true negatives for all other classes into 1,1\n",
    "    new[1,1] = tn\n",
    "    #set false negatives for indicated index into 1,0\n",
    "    new[1,0] = fn\n",
    "    #set negatives for other\n",
    "    new[0,1] = fp\n",
    "    \n",
    "    return new\n",
    "\n",
    "def details_cm(cm, i):\n",
    "    #convert to 2x2\n",
    "    cm = cm_to_2x2(cm, i)\n",
    "    \n",
    "    #calc\n",
    "    details = {\n",
    "        'recall': cm[0,0] / (cm[0,0] + cm[1,0]),\n",
    "        'specificity': cm[1,1] / (cm[1,1] + cm[0,1]),\n",
    "        'precision': cm[0,0] / (cm[0,0] + cm[0, 1]),\n",
    "        'cm_2x2': cm\n",
    "    }\n",
    "    details['f1'] = 2 * details['precision'] * details['recall'] / (details['precision'] + details['recall'])\n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4841b3e-31d9-4327-92c1-d2667195afab",
   "metadata": {},
   "source": [
    "**(5 points)** Test your implementation using the following confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71dc93f3-b2ac-4090-b152-ec0d09773fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  1,  0],\n",
       "       [ 2, 23,  1],\n",
       "       [ 1,  3, 30]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = np.array([29, 1, 0, 2, 23, 1, 1, 3, 30]).reshape(3,3)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d555439c-a73e-4e3b-9ba6-9350ad558f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----class 0----\n",
      "{'recall': 0.90625, 'specificity': 0.9827586206896551, 'precision': 0.9666666666666667, 'cm_2x2': array([[29.,  1.],\n",
      "       [ 3., 57.]]), 'f1': 0.9354838709677419}\n",
      "----class 1----\n",
      "{'recall': 0.8518518518518519, 'specificity': 0.9523809523809523, 'precision': 0.8846153846153846, 'cm_2x2': array([[23.,  3.],\n",
      "       [ 4., 60.]]), 'f1': 0.8679245283018868}\n",
      "----class 2----\n",
      "{'recall': 0.967741935483871, 'specificity': 0.9322033898305084, 'precision': 0.8823529411764706, 'cm_2x2': array([[30.,  4.],\n",
      "       [ 1., 55.]]), 'f1': 0.923076923076923}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cm)):\n",
    "    print(f'----class {i}----')\n",
    "    print(details_cm(cm, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb201ca-a9d0-495e-b4d9-371661f2f0fb",
   "metadata": {},
   "source": [
    "**(15 points)** Using the function and confusion matrix above, calculate the micro and macro $F_1$ scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4dabfda-4e60-468d-9084-317a188c8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = len(cm)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4fedb78-c513-4aa5-90be-311913b254b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389312977099237"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#micro F1\n",
    "mf1_TP = sum([details_cm(cm,i)['cm_2x2'][0,0] for i in range(classes)])\n",
    "mf1_FP = sum([details_cm(cm,i)['cm_2x2'][0,1] for i in range(classes)])\n",
    "mf1_FN = sum([details_cm(cm,i)['cm_2x2'][1,0] for i in range(classes)]) / classes\n",
    "\n",
    "mf1 = mf1_TP / (mf1_TP + 0.5 * (mf1_FP + mf1_FN))\n",
    "mf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45a9f06-ac3a-4a2f-a37d-a63d7213bfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088284407821838"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#macro F1\n",
    "Mf1 = sum([details_cm(cm,i)['f1'] for i in range(classes)]) / classes\n",
    "Mf1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
