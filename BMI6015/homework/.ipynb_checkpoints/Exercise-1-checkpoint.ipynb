{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64deb005-9478-4bae-8568-e03828daefe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5667b8-f52d-475c-a5d3-bc8b61914ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c5112a-375e-474d-80db-4b5e863f63a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART A - NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540976e6-5b65-4250-a8dd-5fb2768b98f6",
   "metadata": {},
   "source": [
    "* **(10 points)** Create a random dataset with 1000 rows and 6 columns by generating the columns one at a time and then concatenating them to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f55f469-53d6-410c-81d7-35fd8e7e39ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "[[  0.18171411  -9.          -4.          -1.          -9.\n",
      "   -6.        ]\n",
      " [  1.44424247   1.           4.           3.          -8.\n",
      "    2.        ]\n",
      " [  0.56254893   0.           7.          -4.          -6.\n",
      "   -9.        ]\n",
      " ...\n",
      " [  0.06694501   9.         -10.          -1.          -1.\n",
      "    9.        ]\n",
      " [ -0.2515041    6.           2.         -10.           4.\n",
      "   -4.        ]\n",
      " [  2.03804292 -10.          -4.           7.          -5.\n",
      "   -5.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.RandomState(42)\n",
    "\n",
    "dataset = np.random.randn(1000, 1)\n",
    "\n",
    "for col in range(5):\n",
    "    dataset = np.concatenate([dataset, np.random.randint(-10, 10, size=(1000, 1))], axis=1)\n",
    "    \n",
    "print(dataset.shape)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1c1d9-2777-4119-bee7-eade7c1f3b5d",
   "metadata": {},
   "source": [
    "* **(8 points)** Shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b2c75e-5355-45f3-b182-575f54e62840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "[[-0.10015028  7.         -9.          5.          7.         -6.        ]\n",
      " [ 0.14199505  0.         -5.          6.         -6.          6.        ]\n",
      " [ 1.56097254  4.         -1.          7.         -8.         -9.        ]\n",
      " ...\n",
      " [-1.32649761  4.          1.         -3.         -7.         -1.        ]\n",
      " [-1.32092938 -7.          8.          6.          7.          0.        ]\n",
      " [-0.22686072  9.          2.          4.          4.          7.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(dataset)\n",
    "\n",
    "print(dataset.shape)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22810d7b-aa04-4083-9356-af786dbf6ad6",
   "metadata": {},
   "source": [
    "* **(10 points)** Split it using a 60/25/15 split into three sets: training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529dbacd-b1ad-48e2-be97-f0a36f0f5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set shape: (600, 6)\n",
      "Validation Set shape: (250, 6)\n",
      "Test Set shape: (150, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training, validation, test size percentages\n",
    "training, validation, test = 0.6, 0.25, 0.15\n",
    "\n",
    "#get the 2 split indexes (split at 60% and 85%)\n",
    "split_ndx1, split_ndx2 = int(training * len(dataset)), int((training + validation) * len(dataset))\n",
    "\n",
    "training_set, validation_set, test_set = dataset[0:split_ndx1,:], dataset[split_ndx1:split_ndx2,:], dataset[split_ndx2:,:]\n",
    "print(f'''\n",
    "Training Set shape: {training_set.shape}\n",
    "Validation Set shape: {validation_set.shape}\n",
    "Test Set shape: {test_set.shape}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c324f7a-ef29-4cb4-b4fa-b38fade159ee",
   "metadata": {},
   "source": [
    "* **(7 points)** Standardize every column in the training set by subtracting every column by its mean and dividing the result by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ccafb3-f283-497b-ab60-7d085aadd501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 6)\n",
      "[[-0.09789617  1.32225337 -1.49698429  0.98141621  1.33387209 -0.94818383]\n",
      " [ 0.15290275  0.1099713  -0.8073946   1.15455638 -0.96489113  1.14083807]\n",
      " [ 1.6225905   0.80270391 -0.11780491  1.32769656 -1.318547   -1.47043931]\n",
      " ...\n",
      " [ 0.4900142   0.62952076  0.39938736 -0.57684534 -0.78806319 -0.94818383]\n",
      " [ 1.58437154 -1.44867707  1.08897706 -0.92312569 -1.318547    0.79266776]\n",
      " [ 1.03282978 -0.92912761  1.4337719  -1.61568638  0.27290445 -0.2518432 ]]\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "stds = []\n",
    "\n",
    "for col in range(training_set.shape[1]):\n",
    "    col_mean = training_set[:,col].mean()\n",
    "    col_std = training_set[:,col].std()\n",
    "    \n",
    "    means.append(col_mean)\n",
    "    stds.append(col_std)\n",
    "    \n",
    "    training_set[:,col] -= col_mean\n",
    "    training_set[:,col] /= col_std\n",
    "    \n",
    "print(training_set.shape)\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81e553-72a0-4e99-a34c-34297e17ab06",
   "metadata": {},
   "source": [
    "* **(5 points)** Do the same with validation and test sets but using the mean and standard deviation from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b79f66-fe37-4761-b152-3c0cc5c43a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 6)\n",
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "for col in range(training_set.shape[1]):\n",
    "    #validation\n",
    "    validation_set[:,col] -= means[col]\n",
    "    validation_set[:,col] /= stds[col]\n",
    "    \n",
    "    #test set\n",
    "    test_set[:,col] -= means[col]\n",
    "    test_set[:,col] /= stds[col]\n",
    "    \n",
    "print(validation_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dab4a-84cb-4b3e-a927-8f5116aa79c9",
   "metadata": {},
   "source": [
    "## PART B - Pandas\n",
    "* **(6 points)** Take the 1000-row dataset you created in the Numpy part and create a DataFrame with it. Give the columns the names `a` to `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f65dbd3-8d44-4780-a43a-f2e4bb593861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.097896</td>\n",
       "      <td>1.322253</td>\n",
       "      <td>-1.496984</td>\n",
       "      <td>0.981416</td>\n",
       "      <td>1.333872</td>\n",
       "      <td>-0.948184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.152903</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>-0.807395</td>\n",
       "      <td>1.154556</td>\n",
       "      <td>-0.964891</td>\n",
       "      <td>1.140838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.622590</td>\n",
       "      <td>0.802704</td>\n",
       "      <td>-0.117805</td>\n",
       "      <td>1.327697</td>\n",
       "      <td>-1.318547</td>\n",
       "      <td>-1.470439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.552783</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>-0.290202</td>\n",
       "      <td>1.500837</td>\n",
       "      <td>0.096077</td>\n",
       "      <td>1.314923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.011904</td>\n",
       "      <td>-0.409578</td>\n",
       "      <td>1.433772</td>\n",
       "      <td>0.115715</td>\n",
       "      <td>-1.672203</td>\n",
       "      <td>1.489008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e         f\n",
       "0 -0.097896  1.322253 -1.496984  0.981416  1.333872 -0.948184\n",
       "1  0.152903  0.109971 -0.807395  1.154556 -0.964891  1.140838\n",
       "2  1.622590  0.802704 -0.117805  1.327697 -1.318547 -1.470439\n",
       "3 -0.552783  0.975887 -0.290202  1.500837  0.096077  1.314923\n",
       "4 -1.011904 -0.409578  1.433772  0.115715 -1.672203  1.489008"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset, columns=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87278dc3-8643-4454-99e2-8b6e830958dc",
   "metadata": {},
   "source": [
    "* **(6 points)** Shuffle the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e929a5-9825-49dc-930d-70b11fc52006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481905e-de53-403f-9bfe-af2a978a3914",
   "metadata": {},
   "source": [
    "* **(8 points)** Break it using a 60/25/15 split into three dataframes: training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ec8ea5-7f99-4a4a-84b4-f4903ed8499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e5dc3-f327-4e06-8cb1-bc957032a6b5",
   "metadata": {},
   "source": [
    "* **(6 points)** Standardize every column in the training dataframe by subtracting every column by its mean and dividing the result by its standard deviation. Do the same with validation and test dataframes but using the mean and standard deviation from the training dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde72d01-205d-4813-b976-f052e0e04fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435685ef-3b08-4fcc-9354-f0dafcbd7136",
   "metadata": {},
   "source": [
    "* **(4 points)** Save all three dataframes into their own `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc520fa-5ae8-460a-a308-9185f235defc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bd929-25cc-4e99-b885-364ed5b0d42a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PART C - Matplotlib\n",
    "\n",
    "* **(27 points)** Plot the following functions using $2\\ by\\ 3$ subplots. Each plot must have its own title, and its own x and y labels. Make also sure that each plot enough of the function to show its behavior.\n",
    "    * $f(x) = 3 x^2 + 10$\n",
    "    * $f(x) = \\frac{1}{1 + e^{-x}}$\n",
    "    * $f(z) = max(\\alpha z, z)$ where $\\alpha = 0.01$ where $max(...)$ returns the maximum of its arguments.\n",
    "    * $f(x) = sin(x^2)$\n",
    "    * $f(x) = cos(x) + ln(x)$\n",
    "    * $f(x) = tanh(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e28391-fb49-40ee-9bd8-1c56e2a95c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa4630-fd25-4837-a722-d9b4ba985665",
   "metadata": {},
   "source": [
    "* **(3 points)** Save the plot into a file named `e01.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f379f6-8e45-47ed-a015-26ec8d030140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
